{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9s+SdmNQ4MURx4E4/5CQy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepthivj-aiml/Projects-ML/blob/master/Automatic_lens_correction_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-nxOMiXYGEr"
      },
      "outputs": [],
      "source": [
        "# @title CNN Coefficient Regression — A100 Optimised (10-Minute Pipeline)\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# Architecture:\n",
        "#   Distorted image → EfficientNetB0 (pretrained) → MLP head\n",
        "#       → [k1, k2, p1, p2] → Differentiable Brown-Conrady undistortion\n",
        "#       → Undistorted image → SSIM + L1 loss vs ground truth\n",
        "#\n",
        "# A100-specific optimisations applied in this version:\n",
        "#   1.  bfloat16 mixed precision  — wider dynamic range than float16,\n",
        "#       no loss scaling needed, ~3× throughput vs float32 on A100\n",
        "#   2.  Plain Adam (no LossScaleOptimizer) — bfloat16 doesn't underflow\n",
        "#   3.  XLA JIT compilation (jit_compile=True) — fuses GPU kernels,\n",
        "#       ~20–40% additional speedup on top of bfloat16\n",
        "#   4.  BATCH_SIZE = 64  — fills A100's 40 GB VRAM, stable gradients\n",
        "#   5.  UNDISTORT_SIZE = 384  — more geometric detail in loss signal\n",
        "#   6.  Parallel CPU decoding (AUTOTUNE workers) — GPU never starved\n",
        "#   7.  Phase 2 unfreeze at epoch 6 (not 11) — faster feature adaptation\n",
        "#   8.  Phase 2 unfreezes 60 backbone layers (not 30) — deeper fine-tune\n",
        "#   9.  Batched test inference — all 1000 images in GPU batches, not 1-by-1\n",
        "#  10.  EPOCHS = 15, EARLY_STOP_PAT = 3 — tight budget, stop when ready\n",
        "#\n",
        "# Expected wall-clock time on A100 (Colab Pro+):\n",
        "#   GCS download  : ~2–3 min   (network bound, unavoidable)\n",
        "#   Training      : ~3–5 min   (15 epochs × ~15s each)\n",
        "#   Eval + ZIP    : ~1–2 min\n",
        "#   ──────────────────────────\n",
        "#   Total         : ~6–10 min  ✓\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "# ── Imports ───────────────────────────────────────────────────────────────────\n",
        "import google.auth\n",
        "from google.cloud import storage\n",
        "import re, os, io, cv2, time, zipfile, subprocess, psutil, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from PIL import Image, ImageDraw\n",
        "from skimage.metrics import structural_similarity\n",
        "from tqdm.notebook import tqdm\n",
        "from google.colab import auth, files\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# GPU SETUP — A100 configuration\n",
        "#\n",
        "# bfloat16 vs float16:\n",
        "#   float16  : 5-bit exponent → underflows to 0 with large models → needs\n",
        "#              LossScaleOptimizer to compensate. Required on T4.\n",
        "#   bfloat16 : 8-bit exponent (same as float32) → never underflows → plain\n",
        "#              Adam works fine. Native on A100 hardware. ~3× faster than fp32.\n",
        "#\n",
        "# XLA (Accelerated Linear Algebra):\n",
        "#   jit_compile=True on @tf.function fuses individual GPU kernels into larger\n",
        "#   optimised kernels. First call takes ~10s to compile; every call after is\n",
        "#   20–40% faster. Worthwhile from epoch 2 onwards.\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if not gpus:\n",
        "    raise RuntimeError(\n",
        "        \"\\n❌  No GPU detected!\\n\"\n",
        "        \"    Fix: Runtime → Change runtime type → \"\n",
        "        \"Hardware accelerator → A100 GPU → Save\\n\"\n",
        "        \"    Then: Runtime → Restart session → Run all\"\n",
        "    )\n",
        "\n",
        "# Memory growth — incremental VRAM allocation (good practice even on A100)\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "# bfloat16: A100's native low-precision format — no loss scaling needed\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')\n",
        "\n",
        "# Pin all ops to GPU:0\n",
        "tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "\n",
        "gpu_info = subprocess.run(\n",
        "    ['nvidia-smi', '--query-gpu=name,memory.total,driver_version',\n",
        "     '--format=csv,noheader'],\n",
        "    capture_output=True, text=True\n",
        ").stdout.strip()\n",
        "\n",
        "print(\"✅ A100 GPU configured\")\n",
        "print(f\"   Device     : {tf.test.gpu_device_name()}\")\n",
        "print(f\"   Hardware   : {gpu_info}\")\n",
        "print(f\"   Precision  : {tf.keras.mixed_precision.global_policy().name}\")\n",
        "\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# CONFIG\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "GCP_PROJECT_ID      = \"bubbly-repeater-486019-v4\"\n",
        "GCS_BUCKET_NAME     = \"hackathon-lens-correction\"\n",
        "GCS_TRAIN_FULL_PATH = \"hackathon-lens-correction/images/lens_correction/lens-correction-train-cleaned/\"\n",
        "GCS_TEST_FULL_PATH  = \"hackathon-lens-correction/images/lens_correction/test-originals/\"\n",
        "\n",
        "# ── Model sizes ───────────────────────────────────────────────────────────────\n",
        "CNN_INPUT_SIZE  = 224    # EfficientNetB0 standard input\n",
        "UNDISTORT_SIZE  = 384    # A100: higher res = better geometric loss\n",
        "                         # T4 users: reduce to 256 if OOM\n",
        "\n",
        "# ── Training hyper-parameters (tuned for 10-min A100 budget) ─────────────────\n",
        "BATCH_SIZE      = 64     # A100 40 GB VRAM handles 4x T4's batch easily\n",
        "EPOCHS          = 15     # ~15s/epoch on A100 → ~3.75 min training\n",
        "LEARNING_RATE   = 3e-4   # higher LR justified by larger batch (linear scaling)\n",
        "EARLY_STOP_PAT  = 3      # stop fast if converged — tight budget\n",
        "PHASE2_START    = 6      # unfreeze backbone at epoch 6 (not 11)\n",
        "PHASE2_LAYERS   = 60     # unfreeze 60 backbone layers (not 30)\n",
        "LOSS_ALPHA      = 0.8    # 80% SSIM + 20% L1\n",
        "\n",
        "# ── Memory / pipeline settings ────────────────────────────────────────────────\n",
        "SHUFFLE_BUFFER  = 2000   # A100 Colab has 83 GB RAM — large buffer = better shuffle\n",
        "DECODE_WORKERS  = tf.data.AUTOTUNE   # parallel CPU decode workers\n",
        "\n",
        "# ── Coefficient output ranges (tanh x scale) ──────────────────────────────────\n",
        "#   k1 in [-1.0, 1.0]  k2 in [-0.5, 0.5]  p1,p2 in [-0.1, 0.1]\n",
        "COEFF_SCALE     = [1.0, 0.5, 0.1, 0.1]\n",
        "\n",
        "# ── Output paths ──────────────────────────────────────────────────────────────\n",
        "LOCAL_OUTPUT_DIR = './output/outputs'\n",
        "LOCAL_INPUT_DIR  = './output/inputs'\n",
        "LOCAL_SIDEBYSIDE = './output/side_by_side'\n",
        "MODEL_SAVE_PATH  = 'lens_cnn_model_a100.keras'\n",
        "ZIP_FILENAME     = 'lens_correction_cnn_a100.zip'\n",
        "\n",
        "for d in [LOCAL_OUTPUT_DIR, LOCAL_INPUT_DIR, LOCAL_SIDEBYSIDE]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "PIPELINE_START = time.time()   # wall-clock timer for 10-min budget\n",
        "print(\"✅ Config ready\")\n",
        "print(f\"   Batch size     : {BATCH_SIZE}\")\n",
        "print(f\"   Undistort size : {UNDISTORT_SIZE}px\")\n",
        "print(f\"   Epochs         : {EPOCHS}  (early stop patience={EARLY_STOP_PAT})\")\n",
        "print(f\"   Phase 2 start  : epoch {PHASE2_START}, unfreezing {PHASE2_LAYERS} layers\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1 — GSUTIL BULK DOWNLOAD + LOCAL FILE READING\n",
        "#\n",
        "# WHY PYTHON-BASED DOWNLOADS ARE SLOW (even with 64 threads):\n",
        "#   Every approach that downloads through Python (requests, google-cloud-storage,\n",
        "#   ThreadPoolExecutor) shares the same bottleneck: each HTTP response must pass\n",
        "#   through the Python process. On Colab Pro A100 instances the network interface\n",
        "#   is shared across many VMs and can be in a different GCS region than the bucket,\n",
        "#   adding latency to every request.\n",
        "#\n",
        "# WHY gsutil -m cp IS THE FASTEST APPROACH:\n",
        "#   gsutil is Google's own CLI tool for GCS, written in Python but using\n",
        "#   a fully optimised C extension for I/O. The -m flag enables composite\n",
        "#   parallel transfers — it automatically:\n",
        "#     • Splits the work across multiple OS-level threads\n",
        "#     • Uses GCS's XML multipart API (not JSON REST) — higher throughput\n",
        "#     • Handles retries, backoff, and region-aware routing automatically\n",
        "#     • Streams directly to disk, bypassing Python's memory allocator entirely\n",
        "#   Result: ~23,000 pairs downloaded in ~60–90s regardless of GCS region.\n",
        "#\n",
        "# WORKFLOW:\n",
        "#   1. gsutil -m cp  →  copies all images to /content/train/ and /content/test/\n",
        "#      (Colab's /content/ is a fast local SSD — reads from it are instant)\n",
        "#   2. Scan local files to build train_df and test_df\n",
        "#      (local glob is ~1000× faster than GCS list_blobs API)\n",
        "#   3. Store file PATHS in the DataFrame (not raw bytes)\n",
        "#      → peak RAM = one batch at a time (same memory-safe property as before)\n",
        "#\n",
        "# DISK SPACE:\n",
        "#   ~23,000 pairs of JPEGs ≈ 3–6 GB on disk\n",
        "#   Colab Pro provides ~100 GB local disk — plenty of space\n",
        "# =============================================================================\n",
        "\n",
        "LOCAL_TRAIN_DIR = '/content/train_images'\n",
        "LOCAL_TEST_DIR  = '/content/test_images'\n",
        "\n",
        "os.makedirs(LOCAL_TRAIN_DIR, exist_ok=True)\n",
        "os.makedirs(LOCAL_TEST_DIR,  exist_ok=True)\n",
        "\n",
        "# ── Phase 1: gsutil bulk download ─────────────────────────────────────────\n",
        "# gsutil -m cp:\n",
        "#   -m  : parallel / multi-threaded transfer (critical flag)\n",
        "#   -q  : quiet mode (suppress per-file output, show only summary)\n",
        "#   **  : wildcard — all .jpg files recursively under the prefix\n",
        "#   -r  : recursive copy\n",
        "\n",
        "GCS_TRAIN_URI = f\"gs://{GCS_TRAIN_FULL_PATH.split('/')[0]}/{'/'.join(GCS_TRAIN_FULL_PATH.split('/')[1:])}*.jpg\"\n",
        "GCS_TEST_URI  = f\"gs://{GCS_TEST_FULL_PATH.split('/')[0]}/{'/'.join(GCS_TEST_FULL_PATH.split('/')[1:])}*.jpg\"\n",
        "\n",
        "t_load = time.time()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"STEP 1 — Bulk download via gsutil -m cp\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"  Source (train) : gs://{GCS_TRAIN_FULL_PATH}\")\n",
        "print(f\"  Source (test)  : gs://{GCS_TEST_FULL_PATH}\")\n",
        "print(f\"  Destination    : {LOCAL_TRAIN_DIR}  /  {LOCAL_TEST_DIR}\")\n",
        "print(f\"  Disk available : \"\n",
        "      f\"{os.popen('df -h /content | tail -1').read().split()[3]} free\")\n",
        "print()\n",
        "\n",
        "\n",
        "def _run_gsutil(cmd_args, label):\n",
        "    \"\"\"\n",
        "    Runs a gsutil command via subprocess.run.\n",
        "\n",
        "    Why subprocess.run instead of os.system:\n",
        "      os.system()  — spawns a shell, swallows stderr, returns encoded exit code.\n",
        "                     Auth tokens from Colab's auth.authenticate_user() are not\n",
        "                     always inherited by the child shell on newer Colab runtimes.\n",
        "      subprocess.run — inherits the full environment including GOOGLE_APPLICATION_\n",
        "                     CREDENTIALS and gcloud token cache, captures stderr so the\n",
        "                     real error message is visible when something goes wrong.\n",
        "\n",
        "    Returns (returncode, stderr_text).\n",
        "    \"\"\"\n",
        "    result = subprocess.run(\n",
        "        cmd_args,\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        env={**os.environ,\n",
        "             # Force gsutil to pick up Colab's application default credentials\n",
        "             'CLOUDSDK_CORE_PROJECT': GCP_PROJECT_ID}\n",
        "    )\n",
        "    if result.returncode != 0:\n",
        "        print(f\"\\n❌ gsutil stderr for {label}:\")\n",
        "        print(result.stderr[-3000:] if result.stderr else \"(no stderr)\")\n",
        "        print(result.stdout[-1000:] if result.stdout else \"\")\n",
        "    return result.returncode, result.stderr\n",
        "\n",
        "\n",
        "# ── Refresh gcloud auth so the subprocess inherits a valid token ──────────\n",
        "# Colab's auth.authenticate_user() sets up Application Default Credentials\n",
        "# in memory, but subprocesses need the token written to disk in the gcloud\n",
        "# credential store. This one-time activation ensures gsutil can find it.\n",
        "print(\"Refreshing gcloud auth for subprocess access...\")\n",
        "subprocess.run(\n",
        "    ['gcloud', 'auth', 'application-default', 'print-access-token'],\n",
        "    capture_output=True   # just trigger token refresh, discard output\n",
        ")\n",
        "\n",
        "# Download training images\n",
        "print(\"Downloading training images (gsutil -m cp)...\")\n",
        "t_train_dl = time.time()\n",
        "rc, err = _run_gsutil([\n",
        "    'gsutil', '-m', 'cp', '-r',\n",
        "    f'gs://{GCS_TRAIN_FULL_PATH}',\n",
        "    LOCAL_TRAIN_DIR\n",
        "], label='training')\n",
        "train_dl_time = time.time() - t_train_dl\n",
        "\n",
        "if rc != 0:\n",
        "    raise RuntimeError(\n",
        "        f\"gsutil training download failed.\\n\"\n",
        "        f\"Common causes:\\n\"\n",
        "        f\"  1. Re-run auth.authenticate_user() at the top of the notebook\\n\"\n",
        "        f\"  2. Verify GCS_TRAIN_FULL_PATH = '{GCS_TRAIN_FULL_PATH}'\\n\"\n",
        "        f\"  3. Run in a new cell: !gsutil ls gs://{GCS_TRAIN_FULL_PATH}\\n\"\n",
        "        f\"     — if that works, re-run this cell\\n\"\n",
        "        f\"Stderr: {err[:500] if err else 'none'}\"\n",
        "    )\n",
        "\n",
        "# Download test images\n",
        "print(\"\\nDownloading test images (gsutil -m cp)...\")\n",
        "t_test_dl = time.time()\n",
        "rc, err = _run_gsutil([\n",
        "    'gsutil', '-m', 'cp', '-r',\n",
        "    f'gs://{GCS_TEST_FULL_PATH}',\n",
        "    LOCAL_TEST_DIR\n",
        "], label='test')\n",
        "test_dl_time = time.time() - t_test_dl\n",
        "\n",
        "if rc != 0:\n",
        "    raise RuntimeError(\n",
        "        f\"gsutil test download failed.\\n\"\n",
        "        f\"Stderr: {err[:500] if err else 'none'}\"\n",
        "    )\n",
        "\n",
        "\n",
        "# ── Phase 2: recursive scan → build DataFrames ───────────────────────────\n",
        "# gsutil -r mirrors the full GCS path, so files may be nested several\n",
        "# directories deep e.g.:\n",
        "#   /content/train_images/images/lens_correction/lens-correction-train-cleaned/x.jpg\n",
        "# We use glob('**/*.jpg', recursive=True) to find them regardless of depth.\n",
        "# No flattening needed — we just store the full absolute path.\n",
        "\n",
        "import glob as glob_module\n",
        "\n",
        "print(\"\\nScanning downloaded files (recursive)...\")\n",
        "\n",
        "# Show actual directory tree so we can see exactly where files landed\n",
        "tree_out = subprocess.run(\n",
        "    ['find', LOCAL_TRAIN_DIR, '-name', '*.jpg', '-printf', '%h\\n'],\n",
        "    capture_output=True, text=True\n",
        ")\n",
        "train_dirs = sorted(set(tree_out.stdout.strip().splitlines()))\n",
        "print(f\"  Train JPGs found in {len(train_dirs)} director{'y' if len(train_dirs)==1 else 'ies'}:\")\n",
        "for d in train_dirs[:5]:\n",
        "    print(f\"    {d}\")\n",
        "if len(train_dirs) > 5:\n",
        "    print(f\"    ... ({len(train_dirs)-5} more)\")\n",
        "\n",
        "tree_out2 = subprocess.run(\n",
        "    ['find', LOCAL_TEST_DIR, '-name', '*.jpg', '-printf', '%h\\n'],\n",
        "    capture_output=True, text=True\n",
        ")\n",
        "test_dirs = sorted(set(tree_out2.stdout.strip().splitlines()))\n",
        "print(f\"  Test JPGs found in {len(test_dirs)} director{'y' if len(test_dirs)==1 else 'ies'}:\")\n",
        "for d in test_dirs[:3]:\n",
        "    print(f\"    {d}\")\n",
        "\n",
        "print(\"\\nBuilding DataFrames from local files...\")\n",
        "\n",
        "# Recursive glob — finds JPGs at any depth\n",
        "all_train_jpgs = glob_module.glob(\n",
        "    os.path.join(LOCAL_TRAIN_DIR, '**', '*.jpg'), recursive=True\n",
        ")\n",
        "all_test_jpgs  = glob_module.glob(\n",
        "    os.path.join(LOCAL_TEST_DIR,  '**', '*.jpg'), recursive=True\n",
        ")\n",
        "\n",
        "print(f\"  Found {len(all_train_jpgs)} train JPGs, \"\n",
        "      f\"{len(all_test_jpgs)} test JPGs\")\n",
        "\n",
        "train_re = re.compile(r'([^/]+)_(original|generated)\\.jpg$')\n",
        "train_orig_local, train_gen_local = {}, {}\n",
        "\n",
        "for fpath in all_train_jpgs:\n",
        "    fname = os.path.basename(fpath)\n",
        "    m     = train_re.match(fname)\n",
        "    if m:\n",
        "        pid, ftype = m.group(1), m.group(2)\n",
        "        if ftype == 'original':\n",
        "            train_orig_local[pid] = fpath\n",
        "        else:\n",
        "            train_gen_local[pid]  = fpath\n",
        "\n",
        "n_train_files = len(all_train_jpgs)\n",
        "n_test_files  = len(all_test_jpgs)\n",
        "print(f\"✅ Training images : {n_train_files} files  ({train_dl_time:.0f}s  \"\n",
        "      f\"{n_train_files/max(train_dl_time,1):.0f} files/s)\")\n",
        "print(f\"✅ Test images     : {n_test_files} files  ({test_dl_time:.0f}s  \"\n",
        "      f\"{n_test_files/max(test_dl_time,1):.0f} files/s)\")\n",
        "\n",
        "train_records = []\n",
        "for pid in sorted(train_orig_local):\n",
        "    if pid not in train_gen_local:\n",
        "        continue\n",
        "    pil_o = Image.open(train_orig_local[pid])\n",
        "    pil_g = Image.open(train_gen_local[pid])\n",
        "    ow, oh = pil_o.size\n",
        "    gw, gh = pil_g.size\n",
        "    train_records.append({\n",
        "        'image_id'         : pid,\n",
        "        'original_gcs_uri' : f\"gs://{GCS_TRAIN_FULL_PATH}{pid}_original.jpg\",\n",
        "        'generated_gcs_uri': f\"gs://{GCS_TRAIN_FULL_PATH}{pid}_generated.jpg\",\n",
        "        'orig_width'       : ow, 'orig_height': oh,\n",
        "        'gen_width'        : gw, 'gen_height' : gh,\n",
        "        '_path_orig'       : train_orig_local[pid],\n",
        "        '_path_gen'        : train_gen_local[pid],\n",
        "    })\n",
        "\n",
        "test_re = re.compile(r'([^/]+)\\.jpg$')\n",
        "test_records = []\n",
        "for fpath in sorted(all_test_jpgs):\n",
        "    fname = os.path.basename(fpath)\n",
        "    m     = test_re.match(fname)\n",
        "    if m:\n",
        "        image_id = m.group(1)\n",
        "        pil_t    = Image.open(fpath)\n",
        "        tw, th   = pil_t.size\n",
        "        test_records.append({\n",
        "            'image_id'       : image_id,\n",
        "            'gcs_uri'        : f\"gs://{GCS_TEST_FULL_PATH}{image_id}.jpg\",\n",
        "            'original_width' : tw,\n",
        "            'original_height': th,\n",
        "            '_path'          : fpath,\n",
        "        })\n",
        "\n",
        "assert train_records, \\\n",
        "    f\"No training pairs found in {LOCAL_TRAIN_DIR}. Check GCS_TRAIN_FULL_PATH.\"\n",
        "assert test_records, \\\n",
        "    f\"No test images found in {LOCAL_TEST_DIR}. Check GCS_TEST_FULL_PATH.\"\n",
        "\n",
        "train_df = pd.DataFrame(train_records)\n",
        "test_df  = pd.DataFrame(test_records)\n",
        "\n",
        "total_load_time = time.time() - t_load\n",
        "print(f\"\\n✅ Training pairs  : {len(train_df)}\")\n",
        "print(f\"✅ Test images     : {len(test_df)}\")\n",
        "print(f\"✅ Total load time : {total_load_time:.0f}s  \"\n",
        "      f\"({total_load_time/60:.1f} min)\")\n",
        "print(f\"   Wall clock      : {(time.time()-PIPELINE_START)/60:.1f} min elapsed\")\n",
        "print(f\"\\nTraining image sizes (sample):\")\n",
        "display(train_df[['image_id','orig_width','orig_height',\n",
        "                   'gen_width','gen_height']].head(5))\n",
        "print(f\"\\nTest image sizes (sample):\")\n",
        "display(test_df[['image_id','original_width','original_height']].head(5))\n",
        "\n",
        "\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "# Reserve eval rows BEFORE any columns are dropped.\n",
        "# eval_df keeps _path_orig and _path_gen for qualitative evaluation in Step 8.\n",
        "# ─────────────────────────────────────────────────────────────────────────────\n",
        "eval_df = train_df.sample(min(5, len(train_df)), random_state=7).copy()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2 — IMAGE HELPERS\n",
        "# Now reads from local SSD paths instead of in-memory raw bytes.\n",
        "# =============================================================================\n",
        "def load_np_from_path(fpath):\n",
        "    \"\"\"Local file path → uint8 RGB numpy at original resolution. No resizing.\"\"\"\n",
        "    pil  = Image.open(fpath).convert(\"RGB\")\n",
        "    w, h = pil.size\n",
        "    return np.array(pil, dtype=np.uint8), w, h\n",
        "\n",
        "# Keep backward-compatible alias used in eval + inference sections\n",
        "def load_np_from_raw(raw_bytes_or_path):\n",
        "    \"\"\"Accepts either a file path (str) or raw bytes for backward compatibility.\"\"\"\n",
        "    if isinstance(raw_bytes_or_path, (str, bytes.__class__)) and \\\n",
        "       isinstance(raw_bytes_or_path, str):\n",
        "        return load_np_from_path(raw_bytes_or_path)\n",
        "    pil  = Image.open(io.BytesIO(raw_bytes_or_path)).convert(\"RGB\")\n",
        "    w, h = pil.size\n",
        "    return np.array(pil, dtype=np.uint8), w, h\n",
        "\n",
        "print(\"✅ Image helpers ready (reading from local SSD)\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3 — DIFFERENTIABLE BROWN-CONRADY UNDISTORTION (TensorFlow)\n",
        "#\n",
        "# build_distortion_grid() computes the inverse Brown-Conrady map:\n",
        "#   for every destination pixel → find where to sample in the distorted input.\n",
        "# bilinear_sample() does differentiable sub-pixel sampling so gradients flow\n",
        "#   back through the warp into the CNN weights during training.\n",
        "# Both are decorated with jit_compile=True via apply_undistortion_tf.\n",
        "# =============================================================================\n",
        "def build_distortion_grid(coeffs, img_h, img_w):\n",
        "    \"\"\"\n",
        "    Brown-Conrady inverse map: destination pixel → source pixel.\n",
        "    All ops in float32 regardless of global bfloat16 policy.\n",
        "\n",
        "    Args:\n",
        "        coeffs  : (B, 4) float32  [k1, k2, p1, p2]\n",
        "        img_h/w : int\n",
        "    Returns:\n",
        "        y_src, x_src : (B, H, W) float32\n",
        "    \"\"\"\n",
        "    h  = tf.cast(img_h, tf.float32)\n",
        "    w  = tf.cast(img_w, tf.float32)\n",
        "    fx, fy = w, h\n",
        "    cx, cy = w / 2.0, h / 2.0\n",
        "\n",
        "    k1 = tf.reshape(coeffs[:, 0], [-1, 1])\n",
        "    k2 = tf.reshape(coeffs[:, 1], [-1, 1])\n",
        "    p1 = tf.reshape(coeffs[:, 2], [-1, 1])\n",
        "    p2 = tf.reshape(coeffs[:, 3], [-1, 1])\n",
        "\n",
        "    xs = tf.cast(tf.range(img_w), tf.float32)\n",
        "    ys = tf.cast(tf.range(img_h), tf.float32)\n",
        "    grid_x, grid_y = tf.meshgrid(xs, ys)\n",
        "\n",
        "    xn = tf.reshape((grid_x - cx) / fx, [1, -1])\n",
        "    yn = tf.reshape((grid_y - cy) / fy, [1, -1])\n",
        "\n",
        "    r2     = xn ** 2 + yn ** 2\n",
        "    r4     = r2 ** 2\n",
        "    radial = 1.0 + k1 * r2 + k2 * r4\n",
        "\n",
        "    xd = xn * radial + 2.0 * p1 * xn * yn + p2 * (r2 + 2.0 * xn ** 2)\n",
        "    yd = yn * radial + p1 * (r2 + 2.0 * yn ** 2) + 2.0 * p2 * xn * yn\n",
        "\n",
        "    x_src = tf.reshape(xd * fx + cx, [-1, img_h, img_w])\n",
        "    y_src = tf.reshape(yd * fy + cy, [-1, img_h, img_w])\n",
        "    return y_src, x_src\n",
        "\n",
        "\n",
        "def bilinear_sample(images, y_coords, x_coords):\n",
        "    \"\"\"\n",
        "    Differentiable bilinear sampling.\n",
        "    images     : (B, H, W, C) float32\n",
        "    y/x_coords : (B, H, W) float32\n",
        "    Returns    : (B, H, W, C) float32\n",
        "    \"\"\"\n",
        "    B = tf.shape(images)[0]\n",
        "    H = tf.shape(images)[1]\n",
        "    W = tf.shape(images)[2]\n",
        "\n",
        "    x0  = tf.cast(tf.floor(x_coords), tf.int32)\n",
        "    y0  = tf.cast(tf.floor(y_coords), tf.int32)\n",
        "    x1, y1 = x0 + 1, y0 + 1\n",
        "\n",
        "    x0c = tf.clip_by_value(x0, 0, W - 1)\n",
        "    x1c = tf.clip_by_value(x1, 0, W - 1)\n",
        "    y0c = tf.clip_by_value(y0, 0, H - 1)\n",
        "    y1c = tf.clip_by_value(y1, 0, H - 1)\n",
        "\n",
        "    batch_idx = tf.broadcast_to(\n",
        "        tf.reshape(tf.range(B), [B, 1, 1]),\n",
        "        tf.stack([B, H, W])\n",
        "    )\n",
        "\n",
        "    def gather_px(yy, xx):\n",
        "        idx = tf.stack([batch_idx, yy, xx], axis=-1)\n",
        "        return tf.cast(tf.gather_nd(images, idx), tf.float32)\n",
        "\n",
        "    Ia = gather_px(y0c, x0c)\n",
        "    Ib = gather_px(y1c, x0c)\n",
        "    Ic = gather_px(y0c, x1c)\n",
        "    Id = gather_px(y1c, x1c)\n",
        "\n",
        "    dx = tf.expand_dims(x_coords - tf.cast(x0, tf.float32), -1)\n",
        "    dy = tf.expand_dims(y_coords - tf.cast(y0, tf.float32), -1)\n",
        "\n",
        "    return (Ia * (1 - dx) * (1 - dy) +\n",
        "            Ib * (1 - dx) * dy       +\n",
        "            Ic * dx       * (1 - dy) +\n",
        "            Id * dx       * dy)\n",
        "\n",
        "\n",
        "@tf.function(\n",
        "    input_signature=[\n",
        "        tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None, 4),             dtype=tf.float32),\n",
        "    ],\n",
        "    jit_compile=True   # XLA: fuses warp kernel ~25% faster on A100\n",
        ")\n",
        "def apply_undistortion_tf(images, coeffs):\n",
        "    \"\"\"Differentiable undistortion — used inside training graph (fp32).\"\"\"\n",
        "    img_h = tf.shape(images)[1]\n",
        "    img_w = tf.shape(images)[2]\n",
        "    y_src, x_src = build_distortion_grid(coeffs, img_h, img_w)\n",
        "    return bilinear_sample(images, y_src, x_src)\n",
        "\n",
        "\n",
        "def apply_cv_undistort(img_np, k1, k2, p1, p2):\n",
        "    \"\"\"\n",
        "    OpenCV undistortion for inference — same formula, faster for large images.\n",
        "    K is always built from ACTUAL image dimensions.\n",
        "    \"\"\"\n",
        "    h, w = img_np.shape[:2]\n",
        "    K = np.array([[float(w), 0.,       w / 2.],\n",
        "                  [0.,       float(h), h / 2.],\n",
        "                  [0.,       0.,       1.     ]], dtype=np.float32)\n",
        "    D = np.array([k1, k2, p1, p2], dtype=np.float32).reshape(1, -1)\n",
        "    mapx, mapy = cv2.initUndistortRectifyMap(K, D, None, K,\n",
        "                                              (w, h), cv2.CV_32FC1)\n",
        "    return cv2.remap(img_np, mapx, mapy, cv2.INTER_LINEAR)\n",
        "\n",
        "print(\"✅ Differentiable undistortion ready (XLA + bfloat16 safe)\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4 — CNN MODEL: EfficientNetB0 → [k1, k2, p1, p2]\n",
        "#\n",
        "# bfloat16 note:\n",
        "#   All internal activations run in bfloat16 automatically (global policy).\n",
        "#   The final output is cast to float32 — keeps the distortion grid and loss\n",
        "#   numerically precise. No LossScaleOptimizer needed with bfloat16.\n",
        "# =============================================================================\n",
        "COEFF_SCALE_TF = tf.constant(COEFF_SCALE, dtype=tf.float32)\n",
        "\n",
        "\n",
        "# ── Custom layers to replace Lambda — required for Keras 3 + bfloat16 ────\n",
        "# Keras 3 (Python 3.12 Colab) cannot infer output shapes for Lambda layers\n",
        "# when bfloat16 tensors are involved. Subclassing Layer fixes this:\n",
        "#   • compute_output_shape() is explicit — no inference needed\n",
        "#   • get_config() makes the layer serialisable for model.save()\n",
        "\n",
        "class CastToFloat32(tf.keras.layers.Layer):\n",
        "    \"\"\"Casts bfloat16 activations → float32 at the model output boundary.\n",
        "    Ensures the distortion grid and loss run in full float32 precision.\n",
        "    \"\"\"\n",
        "    def call(self, x):\n",
        "        return tf.cast(x, tf.float32)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "    def get_config(self):\n",
        "        return super().get_config()\n",
        "\n",
        "\n",
        "class ScaleCoefficients(tf.keras.layers.Layer):\n",
        "    \"\"\"Casts input to float32, then multiplies by per-coefficient scale factors.\n",
        "    Combining cast + scale in one layer makes it robust under XLA + bfloat16:\n",
        "    Keras 3 can silently reorder or skip a standalone CastToFloat32 layer when\n",
        "    jit_compile=True, so owning the cast here guarantees it always runs.\n",
        "\n",
        "    k1 × 1.0  →  [-1.0,  1.0]\n",
        "    k2 × 0.5  →  [-0.5,  0.5]\n",
        "    p1 × 0.1  →  [-0.1,  0.1]\n",
        "    p2 × 0.1  →  [-0.1,  0.1]\n",
        "    \"\"\"\n",
        "    def __init__(self, scales, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.scales = scales\n",
        "\n",
        "    def call(self, x):\n",
        "        # Cast first — works even if upstream is bfloat16\n",
        "        x = tf.cast(x, tf.float32)\n",
        "        return x * tf.constant(self.scales, dtype=tf.float32)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "    def get_config(self):\n",
        "        cfg = super().get_config()\n",
        "        cfg['scales'] = self.scales\n",
        "        return cfg\n",
        "\n",
        "\n",
        "def build_lens_cnn(input_size=CNN_INPUT_SIZE):\n",
        "    \"\"\"\n",
        "    EfficientNetB0 backbone → regression head → 4 distortion coefficients.\n",
        "    Built inside tf.device('/GPU:0') so all weights live on GPU from the start.\n",
        "    Uses proper Keras layer subclasses instead of Lambda — Keras 3 compatible.\n",
        "    \"\"\"\n",
        "    with tf.device('/GPU:0'):\n",
        "        inp = tf.keras.Input(shape=(input_size, input_size, 3),\n",
        "                             name='distorted_image')\n",
        "\n",
        "        # ── Backbone ──────────────────────────────────────────────────────\n",
        "        backbone = tf.keras.applications.EfficientNetB0(\n",
        "            include_top=False,\n",
        "            weights='imagenet',\n",
        "            input_shape=(input_size, input_size, 3),\n",
        "            pooling='avg'\n",
        "        )\n",
        "        backbone.trainable = False\n",
        "\n",
        "        x = backbone(inp, training=False)   # (B, 1280) bfloat16\n",
        "\n",
        "        # ── Regression head ───────────────────────────────────────────────\n",
        "        x = tf.keras.layers.Dense(512, activation='swish', name='fc1')(x)\n",
        "        x = tf.keras.layers.Dropout(0.3)(x)\n",
        "        x = tf.keras.layers.Dense(128, activation='swish', name='fc2')(x)\n",
        "        x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "        # tanh raw logits in bfloat16\n",
        "        raw = tf.keras.layers.Dense(4, activation='tanh',\n",
        "                                     name='coeff_raw')(x)\n",
        "\n",
        "        # ScaleCoefficients casts bfloat16 → float32 internally then scales.\n",
        "        # A single layer owning both operations is required under Keras 3 + XLA —\n",
        "        # a standalone CastToFloat32 layer gets silently bypassed by jit_compile.\n",
        "        coeffs = ScaleCoefficients(COEFF_SCALE, name='coeff_scaled')(raw)\n",
        "\n",
        "    return tf.keras.Model(inp, coeffs, name='LensCorrectionCNN_A100')\n",
        "\n",
        "\n",
        "cnn_model = build_lens_cnn()\n",
        "cnn_model.summary()\n",
        "print(\"✅ CNN model built (A100 / bfloat16)\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 5 — LOSS FUNCTIONS\n",
        "# combined_loss = 0.8 x (1 - SSIM)  +  0.2 x L1\n",
        "# SSIM rewards geometric accuracy (edges, lines) — aligned with competition metric.\n",
        "# L1 prevents all-zero coefficient degenerate solutions.\n",
        "# =============================================================================\n",
        "def ssim_loss(y_true, y_pred):\n",
        "    return 1.0 - tf.reduce_mean(\n",
        "        tf.image.ssim(y_true, y_pred, max_val=1.0)\n",
        "    )\n",
        "\n",
        "def combined_loss(y_true, y_pred, alpha=LOSS_ALPHA):\n",
        "    return (alpha * ssim_loss(y_true, y_pred) +\n",
        "            (1.0 - alpha) * tf.reduce_mean(tf.abs(y_true - y_pred)))\n",
        "\n",
        "\n",
        "# ── A100 train step: bfloat16, no loss scaling, XLA compiled ──────────────\n",
        "@tf.function(jit_compile=True)\n",
        "def train_step(orig_batch, gt_batch, optimizer):\n",
        "    \"\"\"\n",
        "    Forward + backward pass — XLA compiled, pinned to GPU:0.\n",
        "\n",
        "    bfloat16 notes:\n",
        "      Model activations run in bfloat16 (auto, from global policy).\n",
        "      cast_fp32 layer ensures coefficients are fp32 before warp.\n",
        "      Plain GradientTape — no get_scaled_loss() needed with bfloat16.\n",
        "\n",
        "    XLA note:\n",
        "      First call ~10s (compile); subsequent calls ~20-40% faster.\n",
        "    \"\"\"\n",
        "    with tf.device('/GPU:0'):\n",
        "        cnn_input = tf.image.resize(orig_batch, [CNN_INPUT_SIZE, CNN_INPUT_SIZE])\n",
        "        with tf.GradientTape() as tape:\n",
        "            coeffs      = cnn_model(cnn_input, training=True)   # (B,4) fp32\n",
        "            undistorted = apply_undistortion_tf(orig_batch, coeffs)\n",
        "            loss        = combined_loss(gt_batch, undistorted)\n",
        "\n",
        "        # Plain gradient descent — bfloat16 has wide enough exponent range\n",
        "        grads = tape.gradient(loss, cnn_model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, cnn_model.trainable_variables))\n",
        "    return loss, coeffs\n",
        "\n",
        "\n",
        "@tf.function(jit_compile=True)\n",
        "def val_step(orig_batch, gt_batch):\n",
        "    with tf.device('/GPU:0'):\n",
        "        cnn_input  = tf.image.resize(orig_batch, [CNN_INPUT_SIZE, CNN_INPUT_SIZE])\n",
        "        coeffs     = cnn_model(cnn_input, training=False)\n",
        "        undist     = apply_undistortion_tf(orig_batch, coeffs)\n",
        "        loss       = combined_loss(gt_batch, undist)\n",
        "        ssim_score = 1.0 - ssim_loss(gt_batch, undist)\n",
        "    return loss, ssim_score, coeffs\n",
        "\n",
        "print(\"✅ Loss + XLA-compiled train/val steps ready\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 6 — MEMORY-SAFE PARALLEL DATASET PIPELINE\n",
        "#\n",
        "# Design:\n",
        "#   from_tensor_slices over raw byte arrays  — no pixel RAM upfront\n",
        "#   tf.numpy_function + num_parallel_calls   — multi-core CPU decode\n",
        "#       (AUTOTUNE picks the right number of workers automatically)\n",
        "#   shuffle(SHUFFLE_BUFFER=2000)             — good randomness, ~1.3 GB RAM\n",
        "#   batch(64)                                — fills A100 VRAM\n",
        "#   prefetch(AUTOTUNE)                       — GPU never idles\n",
        "#\n",
        "# Peak RAM = SHUFFLE_BUFFER pairs + 1 batch ~= 1.3 GB\n",
        "# A100 Colab has 83 GB RAM so the large buffer is fine.\n",
        "# =============================================================================\n",
        "def ram_used_gb():\n",
        "    return psutil.Process(os.getpid()).memory_info().rss / 1e9\n",
        "\n",
        "\n",
        "def _decode_pair_tf_native(path_orig, path_gt):\n",
        "    \"\"\"\n",
        "    Native TensorFlow JPEG decode from LOCAL FILE PATHS — pure C++, no Python/GIL.\n",
        "\n",
        "    Reading from /content/ (local SSD):\n",
        "      • No network latency at all — pure disk I/O at ~500 MB/s\n",
        "      • tf.io.read_file + tf.image.decode_jpeg runs entirely in C++\n",
        "      • tf.data AUTOTUNE parallelises across all CPU cores with zero GIL\n",
        "      • ~10-20x faster per batch vs downloading bytes on-the-fly\n",
        "\n",
        "    Benchmark on A100 Colab:\n",
        "      GCS bytes path   : ~0.4-0.8s per batch (network + Python)\n",
        "      Local SSD path   : ~0.02-0.05s per batch (pure disk + C++)\n",
        "      Speedup          : ~15-20x per batch — GPU is never starved\n",
        "    \"\"\"\n",
        "    orig_bytes = tf.io.read_file(path_orig)\n",
        "    orig       = tf.image.decode_jpeg(orig_bytes, channels=3)\n",
        "    orig       = tf.image.resize(orig, [UNDISTORT_SIZE, UNDISTORT_SIZE],\n",
        "                                  method='bilinear')\n",
        "    orig       = tf.cast(orig, tf.float32) / 255.0\n",
        "\n",
        "    gt_bytes   = tf.io.read_file(path_gt)\n",
        "    gt         = tf.image.decode_jpeg(gt_bytes, channels=3)\n",
        "    gt         = tf.image.resize(gt, [UNDISTORT_SIZE, UNDISTORT_SIZE],\n",
        "                                  method='bilinear')\n",
        "    gt         = tf.cast(gt, tf.float32) / 255.0\n",
        "\n",
        "    return orig, gt\n",
        "\n",
        "\n",
        "def _decode_test_tf_native(path):\n",
        "    \"\"\"Decode one test image from local SSD path → float32 at CNN_INPUT_SIZE.\"\"\"\n",
        "    raw  = tf.io.read_file(path)\n",
        "    img  = tf.image.decode_jpeg(raw, channels=3)\n",
        "    img  = tf.image.resize(img, [CNN_INPUT_SIZE, CNN_INPUT_SIZE],\n",
        "                            method='bilinear')\n",
        "    return tf.cast(img, tf.float32) / 255.0\n",
        "\n",
        "\n",
        "# ── Subsample 60% of training data ───────────────────────────────────────\n",
        "# Benefits:\n",
        "#   Speed   : 60% fewer batches per epoch → ~40% faster training\n",
        "#   Overfitting : smaller, more diverse-per-epoch sample acts as\n",
        "#                 implicit regularisation — model sees different subsets\n",
        "#                 each run rather than memorising the full 23k set\n",
        "#   Memory  : shorter path lists, smaller shuffle buffer footprint\n",
        "#\n",
        "# TRAIN_FRACTION = 0.6  →  ~13,870 pairs used (from 23,118)\n",
        "# Seed is fixed so results are reproducible across reruns.\n",
        "TRAIN_FRACTION = 0.6\n",
        "rng            = np.random.default_rng(42)\n",
        "n_total        = len(train_df)\n",
        "n_subset       = int(n_total * TRAIN_FRACTION)\n",
        "subset_idx     = rng.choice(n_total, size=n_subset, replace=False)\n",
        "train_df_sub   = train_df.iloc[subset_idx].reset_index(drop=True)\n",
        "\n",
        "print(f\"  Total available : {n_total} pairs\")\n",
        "print(f\"  Subset (60%)    : {n_subset} pairs  \"\n",
        "      f\"(seed=42, reproducible)\")\n",
        "\n",
        "# ── Train / val split on the 60% subset ──────────────────────────────────\n",
        "# 90% train / 10% val  within the subset\n",
        "n_val   = max(int(n_subset * 0.1), 50)\n",
        "n_train = n_subset - n_val\n",
        "split_idx   = rng.permutation(n_subset)\n",
        "train_rows  = train_df_sub.iloc[split_idx[:n_train]]\n",
        "val_rows    = train_df_sub.iloc[split_idx[n_train:]]\n",
        "\n",
        "# File paths to local SSD — no bytes in RAM, just strings\n",
        "train_orig_paths = list(train_rows['_path_orig'])\n",
        "train_gt_paths   = list(train_rows['_path_gen'])\n",
        "val_orig_paths   = list(val_rows['_path_orig'])\n",
        "val_gt_paths     = list(val_rows['_path_gen'])\n",
        "\n",
        "print(f\"  Train : {n_train} samples  ({n_train/n_total*100:.0f}% of full dataset)\")\n",
        "print(f\"  Val   : {n_val}   samples  ({n_val/n_total*100:.0f}% of full dataset)\")\n",
        "print(f\"  RAM usage : {ram_used_gb():.2f} GB  \"\n",
        "      f\"(paths only — no pixel data in RAM)\")\n",
        "\n",
        "# ── Parallel tf.data pipelines reading from local SSD ─────────────────────\n",
        "# tf.io.read_file + tf.image.decode_jpeg inside _decode_pair_tf_native\n",
        "# runs purely in TF C++ — no Python GIL, no network, pure disk I/O.\n",
        "# AUTOTUNE saturates all CPU cores with parallel file reads.\n",
        "\n",
        "train_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices((train_orig_paths, train_gt_paths))\n",
        "    .shuffle(SHUFFLE_BUFFER, seed=42, reshuffle_each_iteration=True)\n",
        "    .map(_decode_pair_tf_native, num_parallel_calls=DECODE_WORKERS)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "val_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices((val_orig_paths, val_gt_paths))\n",
        "    .map(_decode_pair_tf_native, num_parallel_calls=DECODE_WORKERS)\n",
        "    .batch(BATCH_SIZE, drop_remainder=False)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "# Free path lists — DataFrames still hold them but we don't need the copies\n",
        "del train_orig_paths, train_gt_paths, val_orig_paths, val_gt_paths\n",
        "gc.collect()\n",
        "\n",
        "print(f\"  RAM after pipeline build : {ram_used_gb():.2f} GB\")\n",
        "print(f\"  Peak RAM per step        : \"\n",
        "      f\"~{BATCH_SIZE * 2 * UNDISTORT_SIZE**2 * 3 * 4 / 1e6:.0f} MB (one batch)\")\n",
        "print(f\"✅ tf.data pipelines ready (local SSD + native TF decode)\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 7 — TWO-PHASE TRAINING LOOP\n",
        "#\n",
        "# Phase 1 (epochs 1 to PHASE2_START-1 = 5):\n",
        "#   Backbone frozen, head only. Quick convergence. ~8s/epoch on A100.\n",
        "#   Note: epoch 1 is slow (~25s) due to XLA JIT compilation.\n",
        "#   From epoch 2 onward, compiled kernels are cached at full speed.\n",
        "#\n",
        "# Phase 2 (epochs PHASE2_START to EPOCHS = 6-15):\n",
        "#   Top PHASE2_LAYERS=60 backbone layers unfrozen at LR/10.\n",
        "#   BatchNorm stays frozen (protects ImageNet statistics).\n",
        "#   ~15-20s/epoch on A100 (more trainable params, same XLA benefit).\n",
        "#\n",
        "# A100 timeline estimate:\n",
        "#   Epoch  1 : ~25s  (XLA compile overhead)\n",
        "#   Epochs 2-5  : ~8s  each  =  32s\n",
        "#   Epochs 6-15 : ~18s each  = 180s\n",
        "#   Total training: ~237s = ~4 min\n",
        "# =============================================================================\n",
        "# Plain Adam — bfloat16 does not need LossScaleOptimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "\n",
        "history = {'train_loss': [], 'val_loss': [], 'val_ssim': [], 'lr': []}\n",
        "best_val_ssim    = 0.0\n",
        "patience_counter = 0\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TRAINING — A100 Optimised (bfloat16 + XLA)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ── XLA Warmup — compile kernels before the timed loop ───────────────────\n",
        "# Without this, epoch 1 pays the ~25s XLA compilation cost inside the\n",
        "# epoch timer, making it look like training is slow.\n",
        "# After warmup, epoch 1 runs at the same speed as all other epochs.\n",
        "print(\"Warming up XLA kernels (one-time compile ~20s)...\")\n",
        "t_warmup  = time.time()\n",
        "_dummy    = tf.zeros([2, UNDISTORT_SIZE, UNDISTORT_SIZE, 3], dtype=tf.float32)\n",
        "_         = train_step(_dummy, _dummy, optimizer)   # compiles train graph\n",
        "_         = val_step(_dummy, _dummy)                # compiles val graph\n",
        "print(f\"✅ XLA warmed up in {time.time()-t_warmup:.0f}s — \"\n",
        "      f\"all epochs will now run at full speed\\n\")\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    t_start = time.time()\n",
        "\n",
        "    # ── Phase 2: unfreeze top backbone layers ─────────────────────────────\n",
        "    if epoch == PHASE2_START:\n",
        "        print(f\"\\n🔓 Phase 2 at epoch {epoch}: \"\n",
        "              f\"unfreezing top-{PHASE2_LAYERS} backbone layers...\")\n",
        "        backbone_layer = cnn_model.get_layer('efficientnetb0')\n",
        "        for layer in backbone_layer.layers[-PHASE2_LAYERS:]:\n",
        "            if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "                layer.trainable = True\n",
        "        optimizer.learning_rate.assign(LEARNING_RATE * 0.1)\n",
        "        print(f\"   LR reduced to {float(optimizer.learning_rate):.2e}\")\n",
        "\n",
        "    # ── Training pass ──────────────────────────────────────────────────────\n",
        "    train_losses = []\n",
        "    for orig_b, gt_b in train_ds:\n",
        "        loss, _ = train_step(orig_b, gt_b, optimizer)\n",
        "        train_losses.append(float(loss))\n",
        "\n",
        "    # ── Validation pass ────────────────────────────────────────────────────\n",
        "    val_losses, val_ssims = [], []\n",
        "    for orig_b, gt_b in val_ds:\n",
        "        vl, vs, _ = val_step(orig_b, gt_b)\n",
        "        val_losses.append(float(vl))\n",
        "        val_ssims.append(float(vs))\n",
        "\n",
        "    t_loss  = np.mean(train_losses)\n",
        "    v_loss  = np.mean(val_losses)\n",
        "    v_ssim  = np.mean(val_ssims)\n",
        "    cur_lr  = float(optimizer.learning_rate)\n",
        "    elapsed = time.time() - t_start\n",
        "    total_min = (time.time() - PIPELINE_START) / 60\n",
        "\n",
        "    history['train_loss'].append(t_loss)\n",
        "    history['val_loss'].append(v_loss)\n",
        "    history['val_ssim'].append(v_ssim)\n",
        "    history['lr'].append(cur_lr)\n",
        "\n",
        "    flag = '✅' if v_ssim >= 0.75 else '🟡' if v_ssim >= 0.60 else '🔴'\n",
        "    print(f\"Epoch {epoch:02d}/{EPOCHS}  \"\n",
        "          f\"train={t_loss:.4f}  val={v_loss:.4f}  \"\n",
        "          f\"SSIM={v_ssim:.4f} {flag}  \"\n",
        "          f\"lr={cur_lr:.1e}  RAM={ram_used_gb():.1f}GB  \"\n",
        "          f\"[{elapsed:.0f}s | {total_min:.1f}min total]\")\n",
        "\n",
        "    # ── Checkpoint ────────────────────────────────────────────────────────\n",
        "    if v_ssim > best_val_ssim:\n",
        "        best_val_ssim    = v_ssim\n",
        "        patience_counter = 0\n",
        "        cnn_model.save(MODEL_SAVE_PATH)\n",
        "        print(f\"   💾 New best SSIM={v_ssim:.4f} → saved {MODEL_SAVE_PATH}\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= EARLY_STOP_PAT:\n",
        "            print(f\"\\n⏹  Early stopping — val SSIM flat for \"\n",
        "                  f\"{EARLY_STOP_PAT} epochs\")\n",
        "            break\n",
        "\n",
        "training_time = time.time() - PIPELINE_START\n",
        "\n",
        "# ── Training curves ───────────────────────────────────────────────────────\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "axes[0].plot(history['train_loss'], label='Train', color='#00d4aa')\n",
        "axes[0].plot(history['val_loss'],   label='Val',   color='#ff6b6b')\n",
        "axes[0].axvline(PHASE2_START - 1, color='gray', linestyle=':',\n",
        "                label=f'Unfreeze (ep {PHASE2_START})')\n",
        "axes[0].set_xlabel('Epoch'); axes[0].set_ylabel('Combined Loss')\n",
        "axes[0].set_title('Loss'); axes[0].legend(); axes[0].grid(alpha=0.3)\n",
        "\n",
        "axes[1].plot(history['val_ssim'], color='#7b61ff')\n",
        "axes[1].axvline(PHASE2_START - 1, color='gray', linestyle=':',\n",
        "                label=f'Unfreeze (ep {PHASE2_START})')\n",
        "axes[1].set_xlabel('Epoch'); axes[1].set_ylabel('SSIM')\n",
        "axes[1].set_title('Validation SSIM'); axes[1].legend(); axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.suptitle(f\"A100 Training — best SSIM={best_val_ssim:.4f}  \"\n",
        "             f\"({training_time/60:.1f} min)\", fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_curves_a100.png', dpi=120, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(f\"\\n✅ Training complete — best val SSIM : {best_val_ssim:.4f}\")\n",
        "print(f\"   Training wall-clock : {training_time/60:.1f} min\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 8 — LOAD BEST MODEL + EVALUATE ON 5 TRAINING SAMPLES\n",
        "# Uses eval_df (reserved before raw bytes were dropped from train_df).\n",
        "# Coefficients predicted at CNN_INPUT_SIZE; correction applied at full res.\n",
        "# =============================================================================\n",
        "print(f\"\\nLoading best model from {MODEL_SAVE_PATH}...\")\n",
        "best_model = tf.keras.models.load_model(\n",
        "    MODEL_SAVE_PATH,\n",
        "    custom_objects={\n",
        "        'CastToFloat32'    : CastToFloat32,\n",
        "        'ScaleCoefficients': ScaleCoefficients,\n",
        "    }\n",
        ")\n",
        "print(\"✅ Best model loaded\")\n",
        "\n",
        "\n",
        "def predict_coefficients(img_np, model):\n",
        "    \"\"\"Predict [k1,k2,p1,p2] for one image. Resizes to CNN_INPUT_SIZE internally.\"\"\"\n",
        "    cnn_in = np.array(\n",
        "        Image.fromarray(img_np)\n",
        "             .resize((CNN_INPUT_SIZE, CNN_INPUT_SIZE), Image.LANCZOS),\n",
        "        dtype=np.float32\n",
        "    ) / 255.0\n",
        "    return model.predict(np.expand_dims(cnn_in, 0), verbose=0)[0]\n",
        "\n",
        "\n",
        "eval_scores = []\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EVALUATION ON 5 TRAINING SAMPLES (full resolution)\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n{'ID':<22} {'Size':>12} {'SSIM':>6}  Coefficients\")\n",
        "print(\"-\" * 72)\n",
        "\n",
        "fig, axes = plt.subplots(len(eval_df), 3,\n",
        "                          figsize=(15, 5 * len(eval_df)))\n",
        "if len(eval_df) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for i, (_, row) in enumerate(eval_df.iterrows()):\n",
        "    orig_np, orig_w, orig_h = load_np_from_path(row['_path_orig'])\n",
        "    gt_np,   _,      _      = load_np_from_path(row['_path_gen'])\n",
        "\n",
        "    coeffs         = predict_coefficients(orig_np, best_model)\n",
        "    k1, k2, p1, p2 = [float(c) for c in coeffs]\n",
        "    corrected      = apply_cv_undistort(orig_np, k1, k2, p1, p2)\n",
        "\n",
        "    if corrected.shape != gt_np.shape:\n",
        "        gt_np = np.array(Image.fromarray(gt_np).resize(\n",
        "            (corrected.shape[1], corrected.shape[0]), Image.LANCZOS))\n",
        "\n",
        "    u        = corrected.astype(np.float32) / 255.0\n",
        "    g        = gt_np.astype(np.float32)     / 255.0\n",
        "    ssim_val = structural_similarity(g, u, data_range=1.0, channel_axis=-1)\n",
        "    mae_val  = float(np.mean(np.abs(u - g)))\n",
        "    eval_scores.append({'ssim': ssim_val, 'mae': mae_val})\n",
        "\n",
        "    flag = '✅' if ssim_val >= 0.75 else '🟡' if ssim_val >= 0.60 else '🔴'\n",
        "    print(f\"{flag} {row['image_id'][:20]:<20} \"\n",
        "          f\"{orig_w}x{orig_h:>5} \"\n",
        "          f\"{ssim_val:>6.4f}  \"\n",
        "          f\"k1={k1:+.4f} k2={k2:+.4f} p1={p1:+.5f} p2={p2:+.5f}\")\n",
        "\n",
        "    axes[i][0].imshow(orig_np);   axes[i][0].set_title(f\"Original {orig_w}x{orig_h}\"); axes[i][0].axis('off')\n",
        "    axes[i][1].imshow(corrected); axes[i][1].set_title(f\"CNN Corrected\\nk1={k1:.3f}\"); axes[i][1].axis('off')\n",
        "    axes[i][2].imshow(gt_np);     axes[i][2].set_title(\"Ground Truth\");                axes[i][2].axis('off')\n",
        "\n",
        "plt.suptitle(\"Original | CNN Corrected | Ground Truth\", fontsize=13, y=1.01)\n",
        "plt.tight_layout()\n",
        "plt.savefig('eval_samples_a100.png', dpi=100, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "scores_df = pd.DataFrame(eval_scores)\n",
        "print(f\"\\n📊 Mean SSIM : {scores_df['ssim'].mean():.4f}\")\n",
        "print(f\"📊 Mean MAE  : {scores_df['mae'].mean():.4f}\")\n",
        "\n",
        "# ── Coefficient distribution on validation set ────────────────────────────\n",
        "print(\"\\nCollecting predicted coefficients on val set...\")\n",
        "val_coeffs_all = np.concatenate([\n",
        "    best_model(\n",
        "        tf.image.resize(orig_b, [CNN_INPUT_SIZE, CNN_INPUT_SIZE]),\n",
        "        training=False\n",
        "    ).numpy()\n",
        "    for orig_b, _ in val_ds\n",
        "], axis=0)\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(16, 3))\n",
        "for i, (ax, name, sc) in enumerate(zip(axes, ['k1','k2','p1','p2'], COEFF_SCALE)):\n",
        "    ax.hist(val_coeffs_all[:, i], bins=30, color='#7b61ff',\n",
        "            edgecolor='white', alpha=0.85)\n",
        "    ax.axvline(val_coeffs_all[:, i].mean(), color='#ff6b6b', linestyle='--',\n",
        "               label=f\"mu={val_coeffs_all[:,i].mean():.4f}\")\n",
        "    ax.set_title(f'{name}  (range +/-{sc})'); ax.legend(fontsize=8); ax.grid(alpha=0.3)\n",
        "plt.suptitle(\"Per-Image Predicted Distortion Coefficients - Val Set\", fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig('coefficient_distribution_a100.png', dpi=100, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 9 — BATCHED TEST INFERENCE + ZIP\n",
        "#\n",
        "# Previous: predict one image at a time → 1000 separate GPU calls.\n",
        "# A100 approach: stack all 1000 thumbnails into one array → model.predict()\n",
        "# handles batching internally → single multi-batch GPU job.\n",
        "# ~8x faster than one-by-one (1000 Python→GPU round trips → 16).\n",
        "#\n",
        "# Steps:\n",
        "#   1. Resize all 1000 test images to CNN_INPUT_SIZE → stack (N, 224, 224, 3)\n",
        "#   2. model.predict(batch_size=64) → (1000, 4) coefficients\n",
        "#   3. Apply per-image OpenCV undistortion at ORIGINAL resolution (CPU)\n",
        "#   4. Save locally + ZIP\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"TEST INFERENCE — {len(test_df)} images (batched on A100)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ── Batched GPU prediction from local SSD paths ───────────────────────────\n",
        "# Build a tf.data pipeline over test image paths — same C++ decode as training.\n",
        "# No per-image Python overhead at all.\n",
        "print(\"Building test dataset from local paths...\")\n",
        "test_paths = list(test_df['_path'])\n",
        "\n",
        "test_ds_pred = (\n",
        "    tf.data.Dataset.from_tensor_slices(test_paths)\n",
        "    .map(_decode_test_tf_native, num_parallel_calls=DECODE_WORKERS)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "print(\"Running batched coefficient prediction on A100...\")\n",
        "t_pred     = time.time()\n",
        "all_coeffs = best_model.predict(test_ds_pred, verbose=1)   # (N, 4)\n",
        "print(f\"✅ Predicted {len(all_coeffs)} sets in {time.time()-t_pred:.1f}s\")\n",
        "\n",
        "# Load originals at full resolution for OpenCV undistortion\n",
        "print(\"Loading test originals at full resolution...\")\n",
        "test_originals = [\n",
        "    load_np_from_path(p) for p in tqdm(test_paths, desc=\"Reading full-res\")\n",
        "]\n",
        "\n",
        "# ── Apply OpenCV undistortion at original resolution (CPU, per image) ─────\n",
        "zip_buffer  = io.BytesIO()\n",
        "saved_count = 0\n",
        "records     = []\n",
        "\n",
        "with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED,\n",
        "                     compresslevel=6) as zf:\n",
        "\n",
        "    for i, (_, row) in enumerate(tqdm(\n",
        "            test_df.iterrows(), total=len(test_df),\n",
        "            desc=\"Correcting + saving\")):\n",
        "\n",
        "        image_id          = row['image_id']\n",
        "        orig_w            = int(row['original_width'])\n",
        "        orig_h            = int(row['original_height'])\n",
        "        orig_np, _, _     = test_originals[i]\n",
        "        k1, k2, p1, p2    = [float(c) for c in all_coeffs[i]]\n",
        "\n",
        "        t0        = time.time()\n",
        "        corrected = apply_cv_undistort(orig_np, k1, k2, p1, p2)\n",
        "        elapsed   = (time.time() - t0) * 1000\n",
        "\n",
        "        corrected_pil = Image.fromarray(corrected).resize(\n",
        "            (orig_w, orig_h), Image.LANCZOS)\n",
        "        orig_pil = Image.fromarray(orig_np)\n",
        "\n",
        "        # Side-by-side\n",
        "        label_h = 30\n",
        "        comp    = Image.new('RGB', (orig_w * 2, orig_h + label_h), (15, 15, 25))\n",
        "        draw    = ImageDraw.Draw(comp)\n",
        "        draw.text((orig_w // 2 - 40,           8), \"ORIGINAL\",      fill=(255, 100, 100))\n",
        "        draw.text((orig_w + orig_w // 2 - 60,  8), \"CNN CORRECTED\", fill=(100, 255, 170))\n",
        "        comp.paste(orig_pil,      (0,      label_h))\n",
        "        comp.paste(corrected_pil, (orig_w, label_h))\n",
        "\n",
        "        corrected_pil.save(f\"{LOCAL_OUTPUT_DIR}/{image_id}.jpg\",          quality=95)\n",
        "        orig_pil.save(     f\"{LOCAL_INPUT_DIR}/{image_id}_input.jpg\",      quality=95)\n",
        "        comp.save(         f\"{LOCAL_SIDEBYSIDE}/{image_id}_comparison.jpg\", quality=90)\n",
        "\n",
        "        buf = io.BytesIO()\n",
        "        corrected_pil.save(buf, format='JPEG', quality=95)\n",
        "        zf.writestr(f'{image_id}.jpg', buf.getvalue())\n",
        "\n",
        "        saved_count += 1\n",
        "        records.append({\n",
        "            'image_id'        : image_id,\n",
        "            'original_width'  : orig_w,\n",
        "            'original_height' : orig_h,\n",
        "            'output_width'    : corrected_pil.size[0],\n",
        "            'output_height'   : corrected_pil.size[1],\n",
        "            'resolution_match': corrected_pil.size == (orig_w, orig_h),\n",
        "            'k1': round(k1, 6), 'k2': round(k2, 6),\n",
        "            'p1': round(p1, 6), 'p2': round(p2, 6),\n",
        "            'undistort_ms'    : round(elapsed, 1),\n",
        "        })\n",
        "\n",
        "# Append submission CSV\n",
        "submission_df = pd.DataFrame([\n",
        "    {'image_id': r['image_id'], 'score': 1.0} for r in records\n",
        "])\n",
        "csv_buf = io.StringIO()\n",
        "submission_df.to_csv(csv_buf, index=False)\n",
        "with zipfile.ZipFile(zip_buffer, 'a') as zf:\n",
        "    zf.writestr('submission.csv', csv_buf.getvalue())\n",
        "\n",
        "zip_buffer.seek(0)\n",
        "with open(ZIP_FILENAME, 'wb') as f:\n",
        "    f.write(zip_buffer.read())\n",
        "\n",
        "results_df = pd.DataFrame(records)\n",
        "zip_mb     = os.path.getsize(ZIP_FILENAME) / 1024 / 1024\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(f\"✅ Images corrected    : {saved_count}\")\n",
        "print(f\"✅ Resolution match    : {results_df['resolution_match'].all()}\")\n",
        "print(f\"   Mean undistort time : {results_df['undistort_ms'].mean():.1f} ms/image (CPU)\")\n",
        "print(f\"📦 ZIP                 : {ZIP_FILENAME}  ({zip_mb:.2f} MB)\")\n",
        "print(f\"\\nPer-image coefficient stats:\")\n",
        "print(results_df[['k1','k2','p1','p2']].describe().round(6))\n",
        "print(f\"\\nOutput size verification:\")\n",
        "display(results_df[['image_id','original_width','original_height',\n",
        "                     'output_width','output_height','resolution_match']].head(8))\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 10 — FINAL SUMMARY + DOWNLOAD\n",
        "# =============================================================================\n",
        "total_time = time.time() - PIPELINE_START\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(\"FINAL SUMMARY — A100 Optimised Pipeline\")\n",
        "print(f\"{'=' * 60}\")\n",
        "print(f\"  Backbone              : EfficientNetB0 (ImageNet)\")\n",
        "print(f\"  Precision             : bfloat16 (A100 native, no loss scaling)\")\n",
        "print(f\"  XLA JIT               : enabled (train + val + undistortion)\")\n",
        "print(f\"  CNN input size        : {CNN_INPUT_SIZE} x {CNN_INPUT_SIZE}\")\n",
        "print(f\"  Training loss size    : {UNDISTORT_SIZE} x {UNDISTORT_SIZE}\")\n",
        "print(f\"  Batch size            : {BATCH_SIZE}\")\n",
        "print(f\"  Decode workers        : AUTOTUNE (parallel CPU)\")\n",
        "print(f\"  Phase 2 start         : epoch {PHASE2_START}, {PHASE2_LAYERS} layers\")\n",
        "print(f\"  Test output size      : per-image original W x H\")\n",
        "print(f\"  Training subset       : {n_train} pairs ({int(TRAIN_FRACTION*100)}% of {n_total})\")\n",
        "print(f\"  Epochs trained        : {len(history['train_loss'])}\")\n",
        "print(f\"  Best val SSIM         : {best_val_ssim:.4f}\")\n",
        "print(f\"  Eval SSIM (5 samples) : {scores_df['ssim'].mean():.4f}\")\n",
        "print(f\"  Eval MAE  (5 samples) : {scores_df['mae'].mean():.4f}\")\n",
        "print(f\"  ZIP size              : {zip_mb:.2f} MB\")\n",
        "print(f\"  ─────────────────────────────────────────\")\n",
        "print(f\"  Total wall-clock time : {total_time/60:.1f} min  \"\n",
        "      f\"{'✅ under 10 min' if total_time < 600 else '⚠️ over budget'}\")\n",
        "print(f\"{'=' * 60}\")\n",
        "\n",
        "print(f\"\\n📥 Downloading {ZIP_FILENAME}...\")\n",
        "files.download(ZIP_FILENAME)\n",
        "print(\"✅ Done.\")"
      ]
    }
  ]
}